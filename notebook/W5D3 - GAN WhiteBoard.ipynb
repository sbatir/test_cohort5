{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per request from W5D2, let's walk through a GAN example... ##\n",
    "\n",
    "\n",
    "We're going to create a GAN that takes in Celebrity Face data as the seed. \n",
    "We're going to then initialize it and have it create new values. \n",
    "I'm going to walk you through each component, and I'm happy to answer any questions that you might have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('data_face.zip', 'r') as zf:\n",
    "    zf.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import scipy\n",
    "#from scipy.misc import imread, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup your GAN Class\n",
    "\n",
    "Your challenge is to implement your own custom version of this GAN. \n",
    "Please modify 3 components in the following code, and run the script. \n",
    "Some suggestions include: \n",
    "    adding or changing layers to your generator network\n",
    "    adding or changing layers to your discriminator network \n",
    "    changing your optimizer. \n",
    "## You will have 30 minutes to do this, and 10 minutes to review. \n",
    "### You should learn this over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GAN class\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "\n",
    "        #RGB image as an input\n",
    "        self.img_rows, self.img_cols, self.channels = 28, 28, 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = RMSprop(lr=0.0002, rho=0.9)\n",
    "        #optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "        #optimizer = SGD(lr=0.01, momentum=0.75)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input \n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def get_image(self, image_path, width, height, mode):\n",
    "    \n",
    "        image = Image.open(image_path)\n",
    "        # image = image.resize([width, height], Image.BILINEAR)\n",
    "\n",
    "        #The celebA dataset with human faces was used and cropping the images\n",
    "        #helps to get better results by eliminating the background pixels\n",
    "        if image.size != (width, height):  \n",
    "        # Remove most pixels that aren't part of a face\n",
    "            face_width = face_height = 108\n",
    "            j = (image.size[0] - face_width) // 2\n",
    "            i = (image.size[1] - face_height) // 2\n",
    "            image = image.crop([j, i, j + face_width, i + face_height])\n",
    "            image = image.resize([width, height])\n",
    "    \n",
    "        return np.array(image.convert(mode))\n",
    "\n",
    "    def get_batch(self, image_files, width, height, mode):\n",
    "        data_batch = np.array(\n",
    "            [self.get_image(sample_file, width, height, mode) for sample_file in image_files])\n",
    "\n",
    "        return data_batch    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        \n",
    "        # Directory where the face images are stored\n",
    "        data_dir = './data_face'\n",
    "\n",
    "        # Input the images from the directory\n",
    "        X_train = self.get_batch(glob(os.path.join(data_dir, '*.jpg'))[:5000], 28, 28, 'RGB')\n",
    "        \n",
    "\n",
    "        #Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        # Array initialization for logging of the losses\n",
    "        d_loss_logs_r = []\n",
    "        d_loss_logs_f = []\n",
    "        g_loss_logs = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half the batch size of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)D\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Print the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # Store the losses\n",
    "            d_loss_logs_r.append([epoch, d_loss[0]])\n",
    "            d_loss_logs_f.append([epoch, d_loss[1]])\n",
    "            g_loss_logs.append([epoch, g_loss])\n",
    "\n",
    "\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "\n",
    "        d_loss_logs_r_a = np.array(d_loss_logs_r)\n",
    "        d_loss_logs_f_a = np.array(d_loss_logs_f)\n",
    "        g_loss_logs_a = np.array(g_loss_logs)\n",
    "\n",
    "        # At the end of training plot the losses vs epochs\n",
    "        plt.plot(d_loss_logs_r_a[:,0], d_loss_logs_r_a[:,1], label=\"Discriminator Loss - Real\")\n",
    "        plt.plot(d_loss_logs_f_a[:,0], d_loss_logs_f_a[:,1], label=\"Discriminator Loss - Fake\")\n",
    "        plt.plot(g_loss_logs_a[:,0], g_loss_logs_a[:,1], label=\"Generator Loss\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('GAN')\n",
    "        plt.grid(True)\n",
    "        plt.show() \n",
    "                    \n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = (1/2.5) * gen_imgs + 0.5\n",
    "        \n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"output_images/%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run that GAN! Run that GAN\n",
    "The cell below will allow you to execute this. I recommend to not change the number of epochs so you will have enough time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=2000, batch_size=32, save_interval=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
